{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from IPython import display\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train: (891, 12)\n",
      "Dimensions of test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "#this should be done to test data\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "# passengerid_test_values = np.zeros((418 , 1) , dtype=np.int)\n",
    "# passengerid_test_values[:][0] = test['PassengerId'].values\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print(\"Dimensions of train: {}\".format(train.shape))\n",
    "print(\"Dimensions of test: {}\".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = train[:]\n",
    "all_y = train['Survived']\n",
    "\n",
    "test_passid = test['PassengerId']\n",
    "\n",
    "train_X, eval_X, train_Y, eval_Y = train_test_split(\n",
    "    all_X, all_y, test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mukhtar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Mukhtar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#this should be done to test data\n",
    "def process_age(df,cut_points,label_names):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "cut_points = [-1,0,5,12,18,35,60,100]\n",
    "label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "train_X = process_age(train_X,cut_points,label_names)\n",
    "eval_X = process_age(eval_X,cut_points,label_names)\n",
    "test = process_age(test,cut_points,label_names)\n",
    "\n",
    "\n",
    "# pivot = train.pivot_table(index=\"Age_categories\",values='Survived')\n",
    "# pivot.plot.bar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should be done to test data\n",
    "train_X = train_X[[\"Pclass\",\"Sex\",\"Age_categories\"]]\n",
    "eval_X = eval_X[[\"Pclass\",\"Sex\",\"Age_categories\"]]\n",
    "test = test[[\"Pclass\",\"Sex\",\"Age_categories\"]]\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_X = train_X[train_X.columns[:]].apply(le.fit_transform)\n",
    "eval_X = eval_X[eval_X.columns[:]].apply(le.fit_transform)\n",
    "test = test[test.columns[:]].apply(le.fit_transform)\n",
    "\n",
    "\n",
    "train_X = torch.tensor(train_X[:].values)\n",
    "train_Y = torch.tensor(train_Y[:].values)\n",
    "train_X = train_X.type(torch.FloatTensor)\n",
    "train_Y = train_Y.squeeze_()\n",
    "\n",
    "test = torch.tensor(test[:].values)\n",
    "test = test.type(torch.FloatTensor)\n",
    "test_passid_values = torch.tensor(test_passid[:].values)\n",
    "\n",
    "eval_X = torch.tensor(eval_X[:].values)\n",
    "eval_Y = torch.tensor(eval_Y[:].values)\n",
    "eval_X = eval_X.type(torch.FloatTensor)\n",
    "eval_Y = eval_Y.squeeze_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = test[[\"Pclass\",\"Sex\",\"Age_categories\"]]\n",
    "# Y_test = test[[\"Survived\"]]\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# X_test = X_test[X_test.columns[:]].apply(le.fit_transform)\n",
    "\n",
    "# X_test = torch.tensor(X_train[:].values)\n",
    "# Y_test = torch.tensor(Y_train[:].values)\n",
    "# X_test = X_test.type(torch.FloatTensor)\n",
    "# Y_test = Y_test.squeeze_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: (712, 3)\n",
      "train_Y: (712,)\n",
      "eval_X: (179, 3)\n",
      "eval_Y: (179,)\n",
      "test: (418, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_X:\", tuple(train_X.size()))\n",
    "print(\"train_Y:\", tuple(train_Y.size()))\n",
    "print(\"eval_X:\", tuple(eval_X.size()))\n",
    "print(\"eval_Y:\", tuple(eval_Y.size()))\n",
    "print(\"test:\", tuple(test.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in range(X_train.size(0)):   \n",
    "#     print(train_X.data[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model difinition simple DL calssifier\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(3, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 2)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=lambda_l2) # built-in L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 99999, [LOSS]: 0.436228, [ACCURACY]: 0.805\n"
     ]
    }
   ],
   "source": [
    "for Epoch in range(100000):\n",
    "    y_pred = model(train_X);\n",
    "    \n",
    "    loss = criterion(y_pred,train_Y);\n",
    "    \n",
    "    score, predicted = torch.max(y_pred, 1)\n",
    "    acc = (train_Y == predicted).sum().float() / len(train_Y)\n",
    "    print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (Epoch, loss.item(), acc))\n",
    "    display.clear_output(wait=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOSS]: 0.386985, [ACCURACY]: 0.821\n"
     ]
    }
   ],
   "source": [
    "#evalution\n",
    "y_predict = model(eval_X);\n",
    "    \n",
    "eval_loss = criterion(y_predict,eval_Y);\n",
    "    \n",
    "eval_score, eval_predicted = torch.max(y_predict, 1)\n",
    "eval_acc = (eval_Y == eval_predicted).sum().float() / len(eval_Y)\n",
    "print(\"[LOSS]: %.6f, [ACCURACY]: %.3f\" % (eval_loss.item(), eval_acc))\n",
    "# display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = model(test);\n",
    "        \n",
    "test_score, test_predicted = torch.max(y_test_predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_passid_values: (418,)\n",
      "test_predicted: (418,)\n"
     ]
    }
   ],
   "source": [
    "print(\"test_passid_values:\", tuple(test_passid_values.size()))\n",
    "print(\"test_predicted:\", tuple(test_predicted.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_value = np.empty((418, 1) , dtype=np.int)\n",
    "test_passid = np.empty((418, 1) , dtype=np.int)\n",
    "\n",
    "for t in range(test_predicted.size(0)):   \n",
    "#     print(test_predicted.data[t].numpy())\n",
    "    test_predict_value[t][0] =  test_predicted.data[t].numpy()\n",
    "    test_passid[t][0] =  test_passid_values.data[t].numpy()\n",
    "#     print(test_passid[t][0])\n",
    "\n",
    "# print(\"test_predict_value:\", tuple(test_predict_value.size()))\n",
    "# print(\"test_passid:\", tuple(test_passid.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = {\"PassengerId\":test_passid[:,0],\n",
    "                 \"Survived\":test_predict_value[:,0]}\n",
    "submission = pd.DataFrame(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\" , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
